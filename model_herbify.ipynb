{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a51c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Pretrained Model + Fine Tuning (https://keras.io/api/applications/)\n",
    "# create the base pre-trained model : Xception + global spatial average pooling\n",
    "base_model = Xception(weights='imagenet', input_shape = (299,299,3), include_top=False, pooling = 'avg')\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(256, activation='relu')(x)\n",
    "# and a logistic layer -- 20 classes\n",
    "predictions = Dense(20, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "opt = Adam(lr=0.001, decay = 1e-6, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit(train_generator, epochs=4, validation_data = validation_generator, verbose = 1)\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from Xception. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)\n",
    "\n",
    "# we chose to train the last inception blocks, i.e. we will freeze\n",
    "# the first 125 layers and unfreeze the rest:\n",
    "for layer in model.layers[:125]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[125:]:\n",
    "    layer.trainable = True\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "history = model.fit(train_generator, epochs=10, validation_data = validation_generator, verbose = 1)\n",
    "\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "\n",
    "labels = train_generator.class_indices.keys()\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    " \n",
    "  # predicting images\n",
    "  path = fn\n",
    "  img = image.load_img(path, target_size=(299, 299))\n",
    "  x = image.img_to_array(img)\n",
    "  x = np.expand_dims(x, axis=0)\n",
    "  x = preprocess_input(x)\n",
    "\n",
    "  images = np.vstack([x])\n",
    "  proba = model.predict(images)[0]\n",
    "  plt.imshow(img)\n",
    "  plt.show()\n",
    "  for (label, p) in zip(labels, proba):\n",
    "    print(\"{}: {:.2f}%\".format(label, p * 100))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m69"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
